{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset, Image\n\nds = load_dataset(\"sylvainlapeyrade/kanji_english_meaning\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:50:53.066100Z","iopub.execute_input":"2024-09-18T08:50:53.066550Z","iopub.status.idle":"2024-09-18T08:50:57.772829Z","shell.execute_reply.started":"2024-09-18T08:50:53.066502Z","shell.execute_reply":"2024-09-18T08:50:57.771872Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q --upgrade transformers diffusers ftfy peft","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:50:57.777764Z","iopub.execute_input":"2024-09-18T08:50:57.778378Z","iopub.status.idle":"2024-09-18T08:51:11.205825Z","shell.execute_reply.started":"2024-09-18T08:50:57.778335Z","shell.execute_reply":"2024-09-18T08:51:11.204480Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install numba\n\nfrom numba import cuda\ndevice = cuda.get_current_device()\ndevice.reset()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from base64 import b64encode\n\nimport numpy\nimport torch\nfrom diffusers import AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel, DDPMScheduler, StableDiffusionPipeline, DiffusionPipeline\nfrom diffusers.training_utils import compute_dream_and_update_latents\nfrom huggingface_hub import notebook_login\nfrom torchvision import transforms\n\n# For video display:\nfrom IPython.display import HTML\nfrom matplotlib import pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch import autocast\nfrom tqdm.auto import tqdm\nfrom transformers import CLIPTextModel, CLIPTokenizer, logging\nimport os\n\nfrom accelerate import Accelerator, notebook_launcher\nfrom accelerate.utils import set_seed\nfrom huggingface_hub import create_repo, upload_folder\nfrom diffusers.optimization import get_cosine_schedule_with_warmup\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nimport torch.nn.functional as F\nimport os\nfrom diffusers.utils.torch_utils import is_compiled_module\nfrom diffusers.utils import convert_state_dict_to_diffusers, is_wandb_available\nfrom peft.utils import get_peft_model_state_dict\n\nfrom peft import LoraConfig, get_peft_model\n\ntorch.manual_seed(1)\nif not (Path.home()/'.cache/huggingface'/'token').exists(): notebook_login()\n\n# Supress some unnecessary warnings when loading the CLIPTextModel\nlogging.set_verbosity_error()\n\n# Set device\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nif \"mps\" == torch_device: os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:11.207655Z","iopub.execute_input":"2024-09-18T08:51:11.208544Z","iopub.status.idle":"2024-09-18T08:51:17.688125Z","shell.execute_reply.started":"2024-09-18T08:51:11.208491Z","shell.execute_reply":"2024-09-18T08:51:17.687299Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def cast_training_params(model, dtype):\n    if not isinstance(model, list):\n        model = [model]\n    for m in model:\n        for param in m.parameters():\n            # only upcast trainable parameters into fp32\n            if param.requires_grad:\n                param.data = param.to(dtype)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:17.690541Z","iopub.execute_input":"2024-09-18T08:51:17.691146Z","iopub.status.idle":"2024-09-18T08:51:17.696735Z","shell.execute_reply.started":"2024-09-18T08:51:17.691111Z","shell.execute_reply":"2024-09-18T08:51:17.695736Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pretrained_model_name_or_path = \"bguisard/stable-diffusion-nano-2-1\"\n# pretrained_model_name_or_path = \"CompVis/stable-diffusion-v1-4\"\n# pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2-1-base\"\n\ndef get_models_and_scheduler(pretrained_model_name_or_path):\n    # Load the autoencoder model which will be used to decode the latents into image space.\n    vae = AutoencoderKL.from_pretrained(pretrained_model_name_or_path, subfolder=\"vae\")\n\n    # Load the tokenizer and text encoder to tokenize and encode the text.\n    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n    if \"openai\" in pretrained_model_name_or_path:\n        text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n    else:\n        text_encoder = CLIPTextModel.from_pretrained(pretrained_model_name_or_path, subfolder=\"text_encoder\") ## due to size mismatch \n\n    # The UNet model for generating the latents.\n    unet = UNet2DConditionModel.from_pretrained(pretrained_model_name_or_path, subfolder=\"unet\")\n\n    # The noise scheduler\n    # noise_scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n    noise_scheduler = DDPMScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n    \n    return vae, tokenizer, text_encoder, unet, noise_scheduler\n    \nvae, tokenizer, text_encoder, unet, noise_scheduler = get_models_and_scheduler(pretrained_model_name_or_path)\n\ngradient_accumulation_steps = 1\nweight_dtype = torch.float32\nseed = 42\nset_seed(seed)\n\n# Initialize accelerator and tensorboard logging\naccelerator = Accelerator(\n    mixed_precision=\"fp16\",\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    log_with=\"wandb\",\n    project_dir=os.path.join(\"/kaggle/working/\", \"logs\"),\n)\n\n# freeze parameters of models to save more memory\nunet.requires_grad_(False)\nvae.requires_grad_(False)\ntext_encoder.requires_grad_(False)\n\nif accelerator.mixed_precision == \"fp16\":\n    weight_dtype = torch.float16\nelif accelerator.mixed_precision == \"bf16\":\n    weight_dtype = torch.bfloat16\n\n# Freeze the unet parameters before adding adapters\nfor param in unet.parameters():\n    param.requires_grad_(False)\n\n# Define LoRA configuration\nlora_config = LoraConfig(\n    r=4,  # Rank of the low-rank update\n    lora_alpha=4,  # Scaling factor\n    init_lora_weights=\"gaussian\",\n    target_modules=[\"to_k\", \"to_q\", \"to_v\", \"to_out.0\"],\n)\n\n# Move unet, vae and text_encoder to device and cast to weight_dtype\nunet.to(accelerator.device, dtype=weight_dtype)\nvae.to(accelerator.device, dtype=weight_dtype)\ntext_encoder.to(accelerator.device, dtype=weight_dtype)\n\nunet.add_adapter(lora_config)\n\ncast_training_params(unet, dtype=torch.float32)\n\nlora_layers = filter(lambda p: p.requires_grad, unet.parameters())\n\noptimizer = torch.optim.AdamW(lora_layers, lr=0.00001, betas=(0.9, 0.999), weight_decay=1e-2)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:17.698488Z","iopub.execute_input":"2024-09-18T08:51:17.698775Z","iopub.status.idle":"2024-09-18T08:51:22.792961Z","shell.execute_reply.started":"2024-09-18T08:51:17.698745Z","shell.execute_reply":"2024-09-18T08:51:22.792157Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:500: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"def model_size_in_params(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total Parameters: {total_params:,}\")\n    return total_params\ndef model_size_in_mb(model):\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.nelement() * param.element_size()\n    buffer_size = 0\n    for buffer in model.buffers():\n        buffer_size += buffer.nelement() * buffer.element_size()\n    total_size = (param_size + buffer_size) / (1024**2)  # Convert to MB\n    print(f\"Model Size: {total_size:.2f} MB\")\n    return total_size\n\ndef pil_to_latents(pil):\n    img = transforms.ToTensor()(pil).unsqueeze(0).to(torch_device) ## *2 -1 (inside the encode)\n    with torch.no_grad():\n        latent = vae.encode(img) \n    return 0.1825 * latent.latent_dist.sample()\n\ndef latents_to_pil(latents):\n    # bath of latents -> list of images\n    latents = (1 / 0.18215) * latents\n    with torch.no_grad():\n        image = vae.decode(latents).sample\n    image = (image / 2 + 0.5).clamp(0, 1)\n    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n    images = (image * 255).round().astype(\"uint8\")\n    pil_images = [Image.fromarray(image) for image in images]\n    return pil_images\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.794136Z","iopub.execute_input":"2024-09-18T08:51:22.794490Z","iopub.status.idle":"2024-09-18T08:51:22.804920Z","shell.execute_reply.started":"2024-09-18T08:51:22.794455Z","shell.execute_reply":"2024-09-18T08:51:22.803729Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_text_embs_orig(prompts):\n    batch_size = len(prompts)\n    cond_tokens = tokenizer(prompts, padding='max_length', max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        cond_embs = text_encoder(cond_tokens.input_ids.to(accelerator.device), return_dict=False)[0]\n    return cond_embs\n\ndef get_text_embs(prompts):\n    batch_size = len(prompts)\n    cond_tokens = tokenizer(prompts, padding='max_length', max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        cond_embs = text_encoder(cond_tokens.input_ids.to(accelerator.device))[0]\n    max_length = cond_embs.shape[-1]\n    uncond_tokens = tokenizer([''] * batch_size, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        uncond_embs = text_encoder(uncond_tokens.input_ids.to(accelerator.device))[0]\n    text_embs = torch.cat([uncond_embs, cond_embs])\n    return text_embs\n\ndef get_latent_embs(img_tensors, dtype=None):\n    with torch.no_grad():\n        if dtype: img_tensors = img_tensors.to(dtype=weight_dtype)\n        latents = vae.encode(img_tensors)\n    return 0.1825 * latents.latent_dist.sample()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.806177Z","iopub.execute_input":"2024-09-18T08:51:22.806804Z","iopub.status.idle":"2024-09-18T08:51:22.826463Z","shell.execute_reply.started":"2024-09-18T08:51:22.806761Z","shell.execute_reply":"2024-09-18T08:51:22.825650Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"width = 128 \nheight = 128\ndef plot_image(data):\n    img = data['image'].permute(1, 2, 0).cpu().numpy()\n    img = (img * 255).round().astype(\"uint8\")\n    return data['labels'], Image.fromarray(img)\npreprocess = transforms.Compose([\n            transforms.Resize((width, height)),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5], [0.5])\n            ])\ndef transform(examples):\n    images = [preprocess(img) for img in examples['image']]\n    labels = [label for label in examples['text']]\n    return {'image': images, 'labels': labels}\n\nds.set_transform(transform)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.827537Z","iopub.execute_input":"2024-09-18T08:51:22.827851Z","iopub.status.idle":"2024-09-18T08:51:22.846591Z","shell.execute_reply.started":"2024-09-18T08:51:22.827819Z","shell.execute_reply":"2024-09-18T08:51:22.845696Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataloader = torch.utils.data.DataLoader(ds, shuffle=True, batch_size=20)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.847557Z","iopub.execute_input":"2024-09-18T08:51:22.847837Z","iopub.status.idle":"2024-09-18T08:51:22.857157Z","shell.execute_reply.started":"2024-09-18T08:51:22.847807Z","shell.execute_reply":"2024-09-18T08:51:22.856414Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = get_cosine_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=(len(dataloader) * 1000),\n)\n\nunet, optimizer, dataloader, lr_scheduler, vae, text_encoder = accelerator.prepare(\n    unet, optimizer, dataloader, lr_scheduler, vae, text_encoder\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.858227Z","iopub.execute_input":"2024-09-18T08:51:22.858565Z","iopub.status.idle":"2024-09-18T08:51:22.932894Z","shell.execute_reply.started":"2024-09-18T08:51:22.858533Z","shell.execute_reply":"2024-09-18T08:51:22.932206Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"def unwrap_model(model):\n    model = accelerator.unwrap_model(model)\n    model = model._orig_mod if is_compiled_module(model) else model\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.933893Z","iopub.execute_input":"2024-09-18T08:51:22.934194Z","iopub.status.idle":"2024-09-18T08:51:22.938540Z","shell.execute_reply.started":"2024-09-18T08:51:22.934160Z","shell.execute_reply":"2024-09-18T08:51:22.937670Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"save_image_epochs = 3\nsave_model_epochs = 10\nnum_epochs = 1000\noutput_dir = '/kaggle/working/checkpoints'\ngenerator = torch.manual_seed(0)\nmax_grad_norm = 1.0\nguidance_scale = 8.5\n\ndef make_image_grid(imgs, rows, cols):\n    w,h = imgs[0].size\n    grid = Image.new('RGB', size=(cols*w, rows*h))\n    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n    return grid\n\n\ndef validation(pipeline, accelerator, width, height, epoch):\n    validation_prompts = ['a kanji meaning fire', 'a golf course', 'a kanji meaning rage, excitement']\n    num_inference_steps = 50\n\n    pipeline = pipeline.to(accelerator.device)\n    \n    images = []\n    autocast_ctx = torch.autocast(accelerator.device.type)\n    with autocast_ctx:\n        for i in range(len(validation_prompts)):\n            image = pipeline(validation_prompts[i], num_inference_steps=num_inference_steps, generator=generator, width=width, height=height).images[0]\n            images.append(image)\n        \n    # Make a grid out of the images and save them\n    image_grid = make_image_grid(images, rows=1, cols=3)\n\n    # Save the images\n    test_dir = os.path.join(\"/kaggle/working/\", \"samples\")\n    os.makedirs(test_dir, exist_ok=True)\n    image_grid.save(f\"{test_dir}/{epoch:04d}.png\")\n\ndef training_loop(unet, num_epoch=10, cfg=False):\n    max_train_step = 100000\n    \n    if accelerator.is_main_process:\n        if output_dir is not None:\n            os.makedirs(output_dir, exist_ok=True)\n        accelerator.init_trackers(\"sd_kanjivg\")\n        \n    global_step = 0\n    # Now you train the model\n    for epoch in range(num_epochs):\n        progress_bar = tqdm(total=len(dataloader), disable=not accelerator.is_local_main_process)\n        progress_bar.set_description(f\"Epoch {epoch}\")\n        train_loss = 0.0\n        unet.train()\n#         noise_scheduler.set_timesteps(noise_scheduler.config.num_train_timesteps)\n\n        for step, batch in enumerate(dataloader):\n            with accelerator.accumulate(unet):\n                clean_images = batch['image']\n                latents = get_latent_embs(clean_images, dtype=weight_dtype)\n                if cfg:\n                    latents = torch.cat([latents] * 2)\n                noise = torch.rand_like(latents)\n                target = noise\n                bs = clean_images.shape[0]\n                timestep = torch.randint(\n                0, noise_scheduler.config.num_train_timesteps, (latents.shape[0],)\n                )\n                timestep = timestep.long()\n                noisy_latents = noise_scheduler.add_noise(latents, noise, timestep) ## for DDPMS scheduler \n#                 noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps=noise_scheduler.timesteps[timestep])\n                timestep = timestep.to(accelerator.device)\n                if cfg:\n                    encoder_hidden_states = get_text_embs(batch['labels'])\n                else:\n                    encoder_hidden_states = get_text_embs_orig(batch['labels'])\n#                 unet = unet.to(accelerator.device)\n                model_pred = unet(noisy_latents, timestep, encoder_hidden_states, return_dict=False)[0]\n                if cfg:\n                    noise_pred_uncond, noise_pred_text = model_pred.chunk(2)\n                    # Classifier-free guidance prediction\n                    model_pred = torch.cat([noise_pred_uncond, guidance_scale * (noise_pred_text - noise_pred_uncond)])\n\n                loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n                # Gather the losses across all processes for logging (if we use distributed training).\n                avg_loss = accelerator.gather(loss.repeat(latents.shape[0])).mean()\n                train_loss += avg_loss.item() / gradient_accumulation_steps\n\n                # Backpropagate\n                accelerator.backward(loss)\n                if accelerator.sync_gradients:\n                    params_to_clip = lora_layers\n                    accelerator.clip_grad_norm_(params_to_clip, max_grad_norm)\n                optimizer.step()\n                lr_scheduler.step()\n                optimizer.zero_grad()\n\n                progress_bar.update(1)\n                logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n                progress_bar.set_postfix(**logs)\n                accelerator.log(logs, step=global_step)\n                global_step += 1\n\n        # After each epoch you optionally sample some demo images with evaluate() and save the model\n        if accelerator.is_main_process:\n\n            if (epoch + 1) % save_image_epochs == 0 or epoch == num_epochs - 1:\n                pipeline = DiffusionPipeline.from_pretrained(\n                    pretrained_model_name_or_path,\n                    unet=unwrap_model(unet),\n                    revision=None,\n                    variant=None,\n                    torch_dtype=weight_dtype,\n                )\n                validation(pipeline, accelerator, width, height, epoch)\n                del pipeline\n\n            if (epoch + 1) % save_model_epochs == 0 or epoch == num_epochs - 1:\n#                 unet.save_pretrained(output_dir)\n                save_path = os.path.join(output_dir, f\"checkpoint-{global_step}\")\n                accelerator.save_state(save_path)\n\n                unwrapped_unet = unwrap_model(unet)\n                unet_lora_state_dict = convert_state_dict_to_diffusers(\n                    get_peft_model_state_dict(unwrapped_unet)\n                )\n\n                StableDiffusionPipeline.save_lora_weights(\n                    save_directory=save_path,\n                    unet_lora_layers=unet_lora_state_dict,\n                    safe_serialization=True,\n                )\n                accelerator.log({\"note\": \"Saved model\"})\n\n        if global_step > max_train_step:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.939720Z","iopub.execute_input":"2024-09-18T08:51:22.940054Z","iopub.status.idle":"2024-09-18T08:51:22.965924Z","shell.execute_reply.started":"2024-09-18T08:51:22.940021Z","shell.execute_reply":"2024-09-18T08:51:22.965038Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pipeline = DiffusionPipeline.from_pretrained(\n                    pretrained_model_name_or_path,\n                    unet=unwrap_model(unet),\n                    revision=None,\n                    variant=None,\n                    torch_dtype=weight_dtype,\n                )\nvalidation(pipeline, accelerator, width, height, epoch=0)\ndel pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loop(unet)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T08:51:22.968763Z","iopub.execute_input":"2024-09-18T08:51:22.969045Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msanketsans97\u001b[0m (\u001b[33msanketsans97-university-of-genoa\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240918_085125-uafe3qve</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg/runs/uafe3qve' target=\"_blank\">driven-oath-36</a></strong> to <a href='https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg' target=\"_blank\">https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg/runs/uafe3qve' target=\"_blank\">https://wandb.ai/sanketsans97-university-of-genoa/sd_kanjivg/runs/uafe3qve</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1a0e89b158433d9cb02d309d035043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8406c831ee54473d9f40f7e06bc1c223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732f7008c6e64ad98fcea6bd6b18c5af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87d0e0e32b134e20a95581e195195707"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nYou have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b084fa6d13f4fa9a6e07499ff1cd73e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235695720bc34d8ca581f6e002416150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d3218dfecd4172b85aa8cf48b750b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5780e41182a1462399627628465e9e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2030bec96e1e46039b77a827a925b87a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47bcd6fcb814471ab9f151ea7059e868"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf6e2b0398e42f894af185677de1a47"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6513bd7aca4445192610dd7f62e7087"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b121cda05847f69bc9d6ce1dc92e87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7094fb7f5b463793d34c1f30c73743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5f1e5b6a44f4e18a07845d93b3c789b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff7ce984c16405a9efcb482a29bd3f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f05e6e38c743f9967933b58729952e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee6e319116574c96ba1119603ce92c9a"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55db285ee9644b61b2c5833b87925a29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee379454eda474d81b762f75753aef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975a0f4233884107b89067525a4deea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8c4a017473e475bb5354bee66b6ed9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07644a2fca8745b68487341bb93855ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a96df5297c04e25ad9ea049e67eb3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78e58a6811ee4424add3659dabd78d09"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011f31823eb649dc868ca2fbed4f076d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e1cc89549f4849b4cab2b74a6e53aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ab9fe40a27431dbdd9139b78b5ab5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe2938ccecc4f3cb7b7fcbaad814214"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b0599a18f84892b6ff68dc6d35ca21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd0abc6112e546ed9b05cfa7c18c1497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2165b27719fd435185d73c364ddd15cc"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312e50a4c2004cbc95d6fe14bc77c2cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8c157dbc284e7a805ecf67f4ce5469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"337dc7f8a645431c86e47d4496dc0432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"379ef86a78914fc1807c0c7d50de3f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5975d4b5871d4c1aa1812473de07f7f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8fdf2136c541ebb38889ca84ccf55c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62427dcb1fdb4b3497168492ce058ee2"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8de126244c74581bec60dad47f0fb16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d3d66ea88714596a681bdd51fa6ba1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a2fed42884a466e9240897151c0ec6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6a37a25f2d4d208d2a442b5dfdcadc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d644c433ae714a3fae767b3f0b481f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0636730bf6bd46be969a0c08742f5a0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36503e2a9da34150bdf4f436aa87b2ef"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25146497ac1840f6b709b2fe232c05e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ee27e342144bcd9bc71e7b7a43cebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a35e84e89ba44029cebb89a99252990"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d253add8c7482a85e82af1e9cdbaca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba852956343546268a648c780d66564c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab2ceb205aa4781bb69dbdba9e88029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7cef6d4ec94ce3b62dab074928dc4d"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52deabbfef5a4adfab19ef604d2a9916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04d1069d539442cfb0dd2210ef4e3d54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d7049d2934481588c52f8076a24f24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080f59988f07446cb39976130544597e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b238bc23c204959a31141d7f700f128"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae5501c897a4643a286832d83ea981b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc60a69da81149f191be9031bf943cbc"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1713d567791483bb3fc13bbc5d67f8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad625cf922c4d93a5320a4fd1d3b92e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42766372768140c0b12a98ad9670131b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b42017981d54709a07a293f844d29d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107a7eda994e4a5b84a94f47c3a71007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94e1daa47a245728fdd42eba217a626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4633e83cd4284ad5acc21d0d89f6f2fa"}},"metadata":{}},{"name":"stderr","text":"You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6afe2d3c7ca14643bc42da5ef3d804c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb2893b210445e8ab92e6dcefc8eae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621112c88ec54069b50222689938497b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/321 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e223e37587447fb0285b9069326966"}},"metadata":{}}]},{"cell_type":"code","source":"# pipeline = DiffusionPipeline.from_pretrained(\n#     \"CompVis/stable-diffusion-v1-4\",\n#     torch_dtype=weight_dtype,\n# )\npipeline = StableDiffusionPipeline.from_pretrained(\"bguisard/stable-diffusion-nano-2-1\", torch_dtype=weight_dtype, safety_checker=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = DiffusionPipeline.from_pretrained(\n                    pretrained_model_name_or_path,\n                    unet=unwrap_model(unet),\n                    revision=None,\n                    variant=None,\n                    torch_dtype=weight_dtype,\n                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = StableDiffusionPipeline.from_pretrained(\n    pretrained_model_name_or_path,\n    vae=accelerator.unwrap_model(vae),\n    text_encoder=accelerator.unwrap_model(text_encoder),\n    tokenizer=tokenizer,\n    unet=accelerator.unwrap_model(unet),\n    safety_checker=None,\n    torch_dtype=weight_dtype,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline.load_lora_weights('/kaggle/working/checkpoints/checkpoint-96')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_prompts = ['a football stadium', 'a golf course', 'a tennis stadium'] \nsample_prompts = ['a kanji meaning Elon Musk', 'a kanji meaning gaming', 'a kanji meaning football']\nimages = []\npipeline = pipeline.to(accelerator.device)\nautocast_ctx = torch.autocast(accelerator.device.type)\nwith autocast_ctx:\n    for p in sample_prompts:\n        images.append(pipeline(p, num_inference_steps=30, generator=generator, height=128, width=128).images[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef make_image_grid(imgs, rows, cols):\n    w,h = imgs[0].size\n    grid = Image.new('RGB', size=(cols*w, rows*h))\n    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n    return grid\n\n@torch.no_grad()\ndef evaluate(seed=42):\n    vae, tokenizer, text_encoder, unet, noise_scheduler = get_models_and_scheduler(pretrained_model_name_or_path)\n    set_seed(seed)\n    # freeze parameters of models to save more memory\n    unet.requires_grad_(False)\n    vae.requires_grad_(False)\n    text_encoder.requires_grad_(False)\n    \n    unet.to(accelerator.device)\n    vae.to(accelerator.device)\n    text_encoder.to(accelerator.device)\n    \n    sample_prompts = ['a kanji meaning Elon Musk', 'a kanji meaning gaming', 'a kanji meaning robot']\n    batch_size = len(sample_prompts)\n    guidance_scale = 12 \n    num_inference_steps = 50\n    generator = torch.manual_seed(0)\n    text_embeddings = get_text_embs_orig(sample_prompts)\n    \n    # Prep Scheduler\n    def set_timesteps(scheduler, num_inference_steps):\n        scheduler.set_timesteps(num_inference_steps)\n#         scheduler.timesteps = scheduler.timesteps.to(torch.float32) # minor fix to ensure MPS compatibility, fixed in diffusers PR 3925\n\n    set_timesteps(noise_scheduler,num_inference_steps)\n\n    # Prep latents\n    latents = torch.randn(\n      (batch_size, unet.config.in_channels, height // 8, width // 8),\n      generator=generator,\n    )\n    latents = latents.to(accelerator.device)\n    latents = latents * noise_scheduler.init_noise_sigma \n    autocast_ctx = torch.autocast(accelerator.device.type)\n    \n    # Loop\n    with autocast_ctx:  # will fallback to CPU if no CUDA; no autocast for MPS\n        for i, t in tqdm(enumerate(noise_scheduler.timesteps), total=len(noise_scheduler.timesteps)):\n            # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n#             latent_model_input = torch.cat([latents] * 2)\n            latent_model_input = latents\n#             sigma = noise_scheduler.sigmas[i]\n            # Scale the latents (preconditioning):\n            # latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5) # Diffusers 0.3 and below\n            latent_model_input = noise_scheduler.scale_model_input(latent_model_input, t)\n            \n\n            # predict the noise residual\n            with torch.no_grad():\n                noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\n#             # perform guidance\n#             noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n#             noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n            # compute the previous noisy sample x_t -> x_t-1\n            latents = noise_scheduler.step(noise_pred, t, latents).prev_sample\n\n        # scale and decode the image latents with vae\n        latents = 1 / 0.18215 * latents.to(accelerator.device)\n        with torch.no_grad():\n            image = vae.decode(latents).sample\n        images = (image / 2 + 0.5).clamp(0, 1)\n        \n    images = images.detach().cpu().permute(0, 2, 3, 1).numpy()\n    images = (images * 255).round().astype(\"uint8\")\n    pil_images = [Image.fromarray(image) for image in images]\n\n    # Make a grid out of the images and save them\n    image_grid = make_image_grid(pil_images, rows=1, cols=3)\n\n    # Save the images\n    test_dir = os.path.join(\"/kaggle/working/\", \"samples\")\n    os.makedirs(test_dir, exist_ok=True)\n    image_grid.save(f\"{test_dir}/test.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf '/kaggle/working/checkpoints'\n!rm -rf '/kaggle/working/logs'\n!rm -rf '/kaggle/working/samples'\n!rm -rf '/kaggle/working/wandb'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls '/kaggle/working/checkpoints/checkpoint-96'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install safetensors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from safetensors.torch import load_file\nfrom peft import PeftModel, LoraConfig\n\n# Path to the directory where LoRA weights are stored\noutput_dir = \"/kaggle/working/checkpoints\"  # Replace this with your output directory\n\n# Load LoRA weights stored in safetensors format\nlora_weights = load_file(f\"{output_dir}/diffusion_pytorch_model.safetensors\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here, you need to map the weights back to their corresponding layers in the UNet\nunet.load_state_dict(lora_weights, strict=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Downloading files**","metadata":{}},{"cell_type":"code","source":"# !cd /kaggle/working\n!zip -r file.zip /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working\")\n!git clone https://github.com/huggingface/diffusers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/diffusers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nos.chdir(\"/kaggle/working/diffusers/examples/text_to_image/\")\n!pip install -r requirements.txt\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!accelerate config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accelerate launch train_text_to_image_lora.py \\\n--pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n--dataset_name=\"sylvainlapeyrade/kanji_english_meaning\" --caption_column=\"text\" \\\n--resolution=128 --random_flip \\\n--train_batch_size=8 \\\n--num_train_epochs=1 --checkpointing_steps=500 \\\n--learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n--seed=42 \\\n--output_dir=\"kanji2english\" \\\n--validation_prompt=\"A kanji meaning Elon Musk\" \\","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}